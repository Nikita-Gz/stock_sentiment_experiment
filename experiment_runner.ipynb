{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains code that downloads stock price and news data from finnhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:15:02.270573Z",
     "start_time": "2022-10-22T13:12:30.699354Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-_kB6-9a2e8",
    "outputId": "fb9dfa1b-8080-4356-bb7f-7f71f099cca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: finnhub-python in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (2.4.15)\n",
      "Requirement already satisfied: requests>=2.22.0 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from finnhub-python) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests>=2.22.0->finnhub-python) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'F:\\NewDriveSync\\MAGISTR\\publications\\1-stocksentiment\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 20.2.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'F:\\NewDriveSync\\MAGISTR\\publications\\1-stocksentiment\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: packaging in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from tensorflow) (49.2.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from tensorflow) (1.23.4)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from tensorflow) (4.4.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.13.0-py2.py3-none-any.whl (174 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\newdrivesync\\magistr\\publications\\1-stocksentiment\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.9.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: h5py, flatbuffers, tensorflow-io-gcs-filesystem, opt-einsum, google-pasta, keras, wheel, astunparse, gast, keras-preprocessing, libclang, grpcio, tensorflow-estimator, wrapt, termcolor, protobuf, absl-py, MarkupSafe, werkzeug, zipp, importlib-metadata, markdown, tensorboard-plugin-wit, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, tensorboard-data-server, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.13.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 h5py-3.7.0 importlib-metadata-5.0.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 werkzeug-2.2.2 wheel-0.37.1 wrapt-1.14.1 zipp-3.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.3 is available.\n",
      "You should consider upgrading via the 'F:\\NewDriveSync\\MAGISTR\\publications\\1-stocksentiment\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install finnhub-python\n",
    "!python -m pip install -q transformers\n",
    "!python -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:21:12.816273Z",
     "start_time": "2022-10-22T13:21:08.836995Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:21:12.881271Z",
     "start_time": "2022-10-22T13:21:12.819272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:18:16.239633Z",
     "start_time": "2022-10-22T13:18:16.234632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:21:12.892277Z",
     "start_time": "2022-10-22T13:21:12.883274Z"
    },
    "id": "03WQ4DlnR5Zq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "finnhub_key = 'YOUR_API_KEY'\n",
    "\n",
    "current_time = time.time_ns() // 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T12:06:33.015587Z",
     "start_time": "2022-10-23T12:06:33.011587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:21:13.136275Z",
     "start_time": "2022-10-22T13:21:13.133276Z"
    },
    "id": "aRKXOaObdYjC"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:21:13.809269Z",
     "start_time": "2022-10-22T13:21:13.804270Z"
    },
    "id": "Q3ZOdakD1lTl"
   },
   "outputs": [],
   "source": [
    "current_milliseconds = time.time_ns() // 1_000_000\n",
    "current_date = str(datetime.datetime.fromtimestamp(current_time // 1000).date())\n",
    "current_date_as_datetime = datetime.datetime.strptime(current_date, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:21:15.004270Z",
     "start_time": "2022-10-22T13:21:14.996273Z"
    },
    "id": "7XDqQBesRTX5"
   },
   "outputs": [],
   "source": [
    "import finnhub\n",
    "finnhub_client = finnhub.Client(api_key=finnhub_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmLnxsllVQrG"
   },
   "source": [
    "# Collecting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YWLheGG4KAC"
   },
   "source": [
    "## Company list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:27:02.174355Z",
     "start_time": "2022-10-22T13:27:02.169358Z"
    },
    "id": "CO5EUCkcaqYu"
   },
   "outputs": [],
   "source": [
    "important_companies = ['AAPL', 'META', 'MSFT', 'AMZN', 'GOOGL']\n",
    "#companies = ['AAPL', 'MMMMMFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:28:06.748537Z",
     "start_time": "2022-10-22T13:28:06.729538Z"
    },
    "id": "1UtOTomw5FHu"
   },
   "outputs": [],
   "source": [
    "all_companies = ['MMM', 'AOS', 'ABT', 'ABBV', 'ABMD', 'ACN', 'ATVI', 'ADM', 'ADBE', 'AAP', 'AMD', 'AES', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'ANTM', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BKR', 'BLL', 'BAC', 'BBWI', 'BAX', 'BDX', 'BRK.B', 'BBY', 'BIO', 'TECH', 'BIIB', 'BLK', 'BK', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'CHRW', 'CDNS', 'CZR', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'CNC', 'CNP', 'CDAY', 'CERN', 'CF', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'COP', 'ED', 'STZ', 'CPRT', 'GLW', 'CTVA', 'COST', 'CTRA', 'CCI', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DTE', 'DUK', 'DRE', 'DD', 'DXC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'LLY', 'EMR', 'ENPH', 'ETR', 'EOG', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'ETSY', 'RE', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'META', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FRC', 'FE', 'FISV', 'FLT', 'FMC', 'F', 'FTNT', 'FTV', 'FBHS', 'FOXA', 'FOX', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GNRC', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GS', 'HAL', 'HBI', 'HAS', 'HCA', 'PEAK', 'HSIC', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'INFO', 'ITW', 'ILMN', 'INCY', 'IR', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JBHT', 'JKHY', 'J', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LEG', 'LDOS', 'LEN', 'LNC', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LUMN', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NWL', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NSC', 'NTRS', 'NOC', 'NLOK', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'OKE', 'ORCL', 'OGN', 'OTIS', 'PCAR', 'PKG', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PENN', 'PNR', 'PBCT', 'PEP', 'PKI', 'PFE', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PTC', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'QCOM', 'PWR', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SEE', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STE', 'SYK', 'SIVB', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'COO', 'HIG', 'HSY', 'MOS', 'TRV', 'DIS', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRMB', 'TFC', 'TWTR', 'TYL', 'TSN', 'USB', 'UDR', 'ULTA', 'UAA', 'UA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VFC', 'VIAC', 'VTRS', 'V', 'VNO', 'VMC', 'WRB', 'GWW', 'WAB', 'WBA', 'WMT', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XLNX', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZION', 'ZTS']\n",
    "all_companies = [company for company in all_companies if company not in important_companies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:28:22.214521Z",
     "start_time": "2022-10-22T13:28:22.210521Z"
    }
   },
   "outputs": [],
   "source": [
    "companies = important_companies + all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:28:25.118978Z",
     "start_time": "2022-10-22T13:28:25.107685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL',\n",
       " 'META',\n",
       " 'MSFT',\n",
       " 'AMZN',\n",
       " 'GOOGL',\n",
       " 'MMM',\n",
       " 'AOS',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ABMD',\n",
       " 'ACN',\n",
       " 'ATVI',\n",
       " 'ADM',\n",
       " 'ADBE',\n",
       " 'AAP',\n",
       " 'AMD',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'AKAM',\n",
       " 'ALK',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMCR',\n",
       " 'AEE',\n",
       " 'AAL',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'ABC',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'T',\n",
       " 'ATO',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'BKR',\n",
       " 'BLL',\n",
       " 'BAC',\n",
       " 'BBWI',\n",
       " 'BAX',\n",
       " 'BDX',\n",
       " 'BRK.B',\n",
       " 'BBY',\n",
       " 'BIO',\n",
       " 'TECH',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'BK',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'BSX',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BRO',\n",
       " 'BF.B',\n",
       " 'CHRW',\n",
       " 'CDNS',\n",
       " 'CZR',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CARR',\n",
       " 'CTLT',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'CE',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CDAY',\n",
       " 'CERN',\n",
       " 'CF',\n",
       " 'CRL',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CTXS',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CMA',\n",
       " 'CAG',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'CTVA',\n",
       " 'COST',\n",
       " 'CTRA',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHI',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DE',\n",
       " 'DAL',\n",
       " 'XRAY',\n",
       " 'DVN',\n",
       " 'DXCM',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DISCA',\n",
       " 'DISCK',\n",
       " 'DISH',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DPZ',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DRE',\n",
       " 'DD',\n",
       " 'DXC',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'LLY',\n",
       " 'EMR',\n",
       " 'ENPH',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'ETSY',\n",
       " 'RE',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FRC',\n",
       " 'FE',\n",
       " 'FISV',\n",
       " 'FLT',\n",
       " 'FMC',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FBHS',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GPS',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GNRC',\n",
       " 'GD',\n",
       " 'GE',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GL',\n",
       " 'GS',\n",
       " 'HAL',\n",
       " 'HBI',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'PEAK',\n",
       " 'HSIC',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HWM',\n",
       " 'HPQ',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IBM',\n",
       " 'IEX',\n",
       " 'IDXX',\n",
       " 'INFO',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'INCY',\n",
       " 'IR',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IFF',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'IPGP',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JBHT',\n",
       " 'JKHY',\n",
       " 'J',\n",
       " 'SJM',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'KSU',\n",
       " 'K',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KLAC',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LHX',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LVS',\n",
       " 'LEG',\n",
       " 'LDOS',\n",
       " 'LEN',\n",
       " 'LNC',\n",
       " 'LIN',\n",
       " 'LYV',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LUMN',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MKTX',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MTCH',\n",
       " 'MKC',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MAA',\n",
       " 'MRNA',\n",
       " 'MHK',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MPWR',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'NDAQ',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NWL',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NLSN',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NLOK',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NXPI',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'ODFL',\n",
       " 'OMC',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'OGN',\n",
       " 'OTIS',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PAYC',\n",
       " 'PYPL',\n",
       " 'PENN',\n",
       " 'PNR',\n",
       " 'PBCT',\n",
       " 'PEP',\n",
       " 'PKI',\n",
       " 'PFE',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PXD',\n",
       " 'PNC',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PTC',\n",
       " 'PEG',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'PVH',\n",
       " 'QRVO',\n",
       " 'QCOM',\n",
       " 'PWR',\n",
       " 'DGX',\n",
       " 'RL',\n",
       " 'RJF',\n",
       " 'RTX',\n",
       " 'O',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RHI',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'SPGI',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SEE',\n",
       " 'SRE',\n",
       " 'NOW',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SNA',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'STE',\n",
       " 'SYK',\n",
       " 'SIVB',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TMUS',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'TDY',\n",
       " 'TFX',\n",
       " 'TER',\n",
       " 'TSLA',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'COO',\n",
       " 'HIG',\n",
       " 'HSY',\n",
       " 'MOS',\n",
       " 'TRV',\n",
       " 'DIS',\n",
       " 'TMO',\n",
       " 'TJX',\n",
       " 'TSCO',\n",
       " 'TT',\n",
       " 'TDG',\n",
       " 'TRMB',\n",
       " 'TFC',\n",
       " 'TWTR',\n",
       " 'TYL',\n",
       " 'TSN',\n",
       " 'USB',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'UAA',\n",
       " 'UA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UNH',\n",
       " 'UHS',\n",
       " 'VLO',\n",
       " 'VTR',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VFC',\n",
       " 'VIAC',\n",
       " 'VTRS',\n",
       " 'V',\n",
       " 'VNO',\n",
       " 'VMC',\n",
       " 'WRB',\n",
       " 'GWW',\n",
       " 'WAB',\n",
       " 'WBA',\n",
       " 'WMT',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WST',\n",
       " 'WDC',\n",
       " 'WU',\n",
       " 'WRK',\n",
       " 'WY',\n",
       " 'WHR',\n",
       " 'WMB',\n",
       " 'WLTW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XLNX',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBRA',\n",
       " 'ZBH',\n",
       " 'ZION',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Zf1Cfx5VVHs"
   },
   "source": [
    "## Collecting stock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "idtCZFQIXokK"
   },
   "outputs": [],
   "source": [
    "def retrieve_stock_prices(company):\n",
    "  response = finnhub_client.stock_candles(company,\n",
    "                                          'D',\n",
    "                                          0,\n",
    "                                          current_time)\n",
    "  if response['s'] == 'no_data':\n",
    "    return None\n",
    "\n",
    "  stocks_df = pd.DataFrame(response)\n",
    "  stocks_df['t'] = pd.to_datetime(stocks_df['t'], unit='s')\n",
    "  stocks_df['t'] = stocks_df['t'].dt.date\n",
    "  stocks_df = stocks_df.set_index('t')\n",
    "  stocks_df = stocks_df.sort_index()\n",
    "  stocks_df = stocks_df[['c', 'h', 'l', 'o', 'v']]\n",
    "  return stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ElbygAlvuqkO"
   },
   "outputs": [],
   "source": [
    "def get_relative_change(stocks_df):\n",
    "  relative_change_df = stocks_df / stocks_df.shift(1) - 1\n",
    "  relative_change_df = relative_change_df.dropna()\n",
    "  return relative_change_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NpWyq9QirGem"
   },
   "outputs": [],
   "source": [
    "# get features for N previous periods\n",
    "def get_previous_features(stocks_df, periods):\n",
    "  previous_periods_frames = []\n",
    "  for period in range(1, periods+1):\n",
    "    previous_period_data = stocks_df.shift(period)\n",
    "\n",
    "    # rename columns to signify previous period\n",
    "    for column in previous_period_data.columns:\n",
    "      previous_period_data.rename({column: str(period) + '_' + column},\n",
    "                                  axis=1,\n",
    "                                  inplace=True)\n",
    "    previous_periods_frames.append(previous_period_data)\n",
    "  return pd.concat(previous_periods_frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QmDqJATGtSSH"
   },
   "outputs": [],
   "source": [
    "def get_companies_stocks(company_list, last_periods):\n",
    "  companies_stock_dataframes = []\n",
    "  for company in company_list:\n",
    "    print(f'Getting stocks for company {company} with {last_periods} periods')\n",
    "\n",
    "    stocks_df = retrieve_stock_prices(company)\n",
    "    if stocks_df is None:\n",
    "      print(f'Did not find stocks for company {company}')\n",
    "      continue\n",
    "\n",
    "    assert stocks_df.isna().sum().sum() == 0\n",
    "\n",
    "    relative_change_df = get_relative_change(stocks_df)\n",
    "\n",
    "    target_column = 'c'\n",
    "    previous_features = get_previous_features(relative_change_df, last_periods)\n",
    "    target_series = pd.Series(relative_change_df[target_column], name='target')\n",
    "    target_features_df = pd.concat([target_series, previous_features], axis=1)\n",
    "\n",
    "    target_features_df['company'] = company\n",
    "    target_features_df = target_features_df.reset_index()\n",
    "    companies_stock_dataframes.append(target_features_df)\n",
    "    time.sleep(1)\n",
    "\n",
    "  all_companies_stocks = pd.concat(companies_stock_dataframes)\n",
    "  return all_companies_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nRb7Y5TcWWI"
   },
   "source": [
    "## Collecting news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-23T11:16:49.469586Z",
     "start_time": "2022-10-23T11:16:49.458589Z"
    },
    "id": "Jxwb7RfqgvGj"
   },
   "outputs": [],
   "source": [
    "# news must be downloaded in packs as API only returns about 240 latest news\n",
    "# up to specified date\n",
    "\n",
    "def get_news_meta_data_pack(company, date):\n",
    "  print(f'Retrieving news for {company} on {date}')\n",
    "  has_retrieved_results = False\n",
    "  while not has_retrieved_results:\n",
    "    try:\n",
    "      api_result = finnhub_client.company_news(company, _from=date, to=date)\n",
    "      has_retrieved_results = True\n",
    "    except:\n",
    "      wait_duration = 10\n",
    "      print(f'Retrying in {wait_duration} seconds')\n",
    "      time.sleep(wait_duration)\n",
    "  \n",
    "  results_df = pd.DataFrame(api_result)\n",
    "\n",
    "  if len(results_df) != 0:\n",
    "    print(f'Got {len(results_df)} news')\n",
    "\n",
    "    # filters out news that may have invalid dates or summaries or content\n",
    "    results_df = results_df[(results_df['url'] != '') &\n",
    "                            (results_df['headline'] != '') &\n",
    "                            (results_df['datetime'] > 0) &\n",
    "                            (results_df['summary'].apply(lambda summary: len(summary.split()) > 0))]\n",
    "    results_df['datetime'] = pd.to_datetime(results_df['datetime'], unit='s')\n",
    "  return results_df\n",
    "\n",
    "# 1) get news up to current date\n",
    "# 2) get earliest date of news\n",
    "# 3) get more news up until that date\n",
    "# 4) continue doing this\n",
    "\n",
    "def get_all_news_for_company(company):\n",
    "  date_to_fetch_from = datetime.datetime(year=current_date_as_datetime.year-1,\n",
    "                                         month=current_date_as_datetime.month,\n",
    "                                         day=current_date_as_datetime.day)\n",
    "  dates_to_fetch = pd.date_range(start=date_to_fetch_from,\n",
    "                                 end=current_date)\n",
    "  all_news_packs = []\n",
    "  for i, date_to_fetch_news_pack_to in enumerate(dates_to_fetch[::-1]):\n",
    "    print(f'{i+1} news out of {len(dates_to_fetch)}')\n",
    "    latest_news_pack = get_news_meta_data_pack(\n",
    "        company=company,\n",
    "        date=str(date_to_fetch_news_pack_to.date()))\n",
    "    \n",
    "    all_news_packs.append(latest_news_pack)\n",
    "    time.sleep(1)\n",
    "    \n",
    "  news_packs_joined = pd.concat(all_news_packs)\n",
    "  news_packs_without_dupes = news_packs_joined.drop_duplicates(subset='id',\n",
    "                                                               keep=\"first\")\n",
    "  news_packs_without_dupes = news_packs_without_dupes.reset_index(drop=True)\n",
    "\n",
    "  print(f'Dupes removed: {len(news_packs_joined) - len(news_packs_without_dupes)}')\n",
    "  print(f'Dataframe size: {len(news_packs_without_dupes)}')\n",
    "\n",
    "  return news_packs_without_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:31:24.067775Z",
     "start_time": "2022-10-22T13:31:22.293807Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZiwEm27j2ihg",
    "outputId": "9b5d8bfb-0653-4764-8e0a-346a3027a883"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def get_sentiment_for_series(text_series):\n",
    "  #sentiments = sentiment_pipeline(list(text_series))\n",
    "  text_series = list(text_series.apply(lambda text: ' '.join(text.split()[:200])))\n",
    "  sentiments = sentiment_pipeline(text_series)\n",
    "\n",
    "  positive_scores = []\n",
    "  negative_scores = []\n",
    "  for i, sentiment in enumerate(sentiments):\n",
    "    label = sentiment['label']\n",
    "    score = sentiment['score']\n",
    "    if label == 'POSITIVE':\n",
    "      positive_scores.append(score)\n",
    "      negative_scores.append(0.0)\n",
    "    elif label == 'NEGATIVE':\n",
    "      positive_scores.append(0.0)\n",
    "      negative_scores.append(score)\n",
    "    else:\n",
    "      raise Exception(f'Unknown sentiment label {label} in sentiment idx {i}')\n",
    "  \n",
    "  sentiments_df = pd.DataFrame({'positive_score': positive_scores,\n",
    "                                'negative_score': negative_scores})\n",
    "  return sentiments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:31:30.311355Z",
     "start_time": "2022-10-22T13:31:30.302351Z"
    },
    "id": "2JOuBd490YMI"
   },
   "outputs": [],
   "source": [
    "def get_sentiment_stats_per_day(sentiments_df):\n",
    "  sentiments_per_day = sentiments_df.groupby(sentiments_df['datetime'].dt.date).agg(\n",
    "      mean_daily_positive_score=('positive_score', lambda series: series[series > 0].mean(skipna=True)),\n",
    "      daily_positives_count=('positive_score', lambda series: (series > 0).sum()),\n",
    "      daily_positives_ratio=('positive_score', lambda series: (series > 0).sum() / len(series)),\n",
    "      mean_daily_negative_score=('negative_score', lambda series: series[series > 0].mean(skipna=True)),\n",
    "      daily_negatives_count=('negative_score', lambda series: (series > 0).sum()),\n",
    "      daily_negatives_ratio=('negative_score', lambda series: (series > 0).sum() / len(series)),\n",
    "      daily_news_count=('negative_score', 'count')\n",
    "  )\n",
    "  sentiments_per_day = sentiments_per_day.fillna(0)\n",
    "\n",
    "  positivity = sentiments_per_day['mean_daily_positive_score'] * sentiments_per_day['daily_positives_ratio']\n",
    "  negativity = sentiments_per_day['mean_daily_negative_score'] * sentiments_per_day['daily_negatives_ratio']\n",
    "\n",
    "  sentiments_per_day['positivity'] = positivity\n",
    "  sentiments_per_day['negativity'] = negativity\n",
    "  sentiments_per_day['mood'] = positivity - negativity\n",
    "\n",
    "  sentiments_per_day.index.name = 'datetime'\n",
    "\n",
    "  return sentiments_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:31:31.581353Z",
     "start_time": "2022-10-22T13:31:31.575353Z"
    },
    "id": "qkSEhvCL3_lg"
   },
   "outputs": [],
   "source": [
    "def fill_missing_days(sentiment_stats_per_day):\n",
    "  # at this moment, index represents dates\n",
    "  sentiment_stats_per_day = sentiment_stats_per_day.sort_index()\n",
    "\n",
    "  day_range = pd.date_range(sentiment_stats_per_day.index.min(), sentiment_stats_per_day.index.max(), freq='D')\n",
    "  len_before_reindex = len(sentiment_stats_per_day)\n",
    "\n",
    "  # todo: decide, fill reindex with 0's or with forward fill?\n",
    "\n",
    "  sentiment_stats_per_day = sentiment_stats_per_day.reindex(day_range, fill_value=0)\n",
    "  sentiment_stats_per_day['no_news_today'] = (sentiment_stats_per_day['daily_news_count'] == 0).astype(float)\n",
    "\n",
    "  print(f'Filled in df is {len(sentiment_stats_per_day) / len_before_reindex} times bigger')\n",
    "\n",
    "  return sentiment_stats_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:31:32.674365Z",
     "start_time": "2022-10-22T13:31:32.663368Z"
    },
    "id": "1ueDrgPq-CFM"
   },
   "outputs": [],
   "source": [
    "# todo: compute buzz relative to 7 days ago\n",
    "# todo: compute score relative to 7 days ago\n",
    "\n",
    "def get_windowed_sentiment_stats(sentiments_per_day):\n",
    "  sentiments_per_day = sentiments_per_day.sort_index()\n",
    "\n",
    "  weekly_buzz = sentiments_per_day['daily_news_count'] / sentiments_per_day.rolling(7, min_periods=1)['daily_news_count'].mean()\n",
    "  monthly_buzz = sentiments_per_day['daily_news_count'] / sentiments_per_day.rolling(30, min_periods=1)['daily_news_count'].mean()\n",
    "\n",
    "  weekly_relative_positivity = sentiments_per_day['positivity'] / sentiments_per_day.rolling(7, min_periods=1)['positivity'].mean()\n",
    "  monthly_relative_positivity = sentiments_per_day['positivity'] / sentiments_per_day.rolling(30, min_periods=1)['positivity'].mean()\n",
    "\n",
    "  weekly_relative_negativity = sentiments_per_day['negativity'] / sentiments_per_day.rolling(7, min_periods=1)['negativity'].mean()\n",
    "  monthly_relative_negativity = sentiments_per_day['negativity'] / sentiments_per_day.rolling(30, min_periods=1)['negativity'].mean()\n",
    "\n",
    "  weekly_relative_mood = sentiments_per_day['mood'] / sentiments_per_day.rolling(7, min_periods=1)['mood'].mean()\n",
    "  monthly_relative_mood = sentiments_per_day['mood'] / sentiments_per_day.rolling(30, min_periods=1)['mood'].mean()\n",
    "\n",
    "  difference_from_mood_week_ago = sentiments_per_day['mood'] - sentiments_per_day.shift(7)['mood']\n",
    "  difference_from_mood_month_ago = sentiments_per_day['mood'] - sentiments_per_day.shift(30)['mood']\n",
    "\n",
    "  sentiments_per_day['weekly_buzz'] = weekly_buzz\n",
    "  sentiments_per_day['monthly_buzz'] = monthly_buzz\n",
    "  sentiments_per_day['weekly_relative_positivity'] = weekly_relative_positivity\n",
    "  sentiments_per_day['monthly_relative_positivity'] = monthly_relative_positivity\n",
    "  sentiments_per_day['weekly_relative_negativity'] = weekly_relative_negativity\n",
    "  sentiments_per_day['monthly_relative_negativity'] = monthly_relative_negativity\n",
    "  sentiments_per_day['weekly_relative_mood'] = weekly_relative_mood\n",
    "  sentiments_per_day['monthly_relative_mood'] = monthly_relative_mood\n",
    "  sentiments_per_day['difference_from_mood_week_ago'] = difference_from_mood_week_ago\n",
    "  sentiments_per_day['difference_from_mood_month_ago'] = difference_from_mood_month_ago\n",
    "\n",
    "  sentiments_per_day['nan_window_data'] = sentiments_per_day.isna().any(axis=1).astype(float)\n",
    "  sentiments_per_day = sentiments_per_day.fillna(0)\n",
    "  return sentiments_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:31:33.851052Z",
     "start_time": "2022-10-22T13:31:33.847051Z"
    },
    "id": "yomYwdJiRYxu"
   },
   "outputs": [],
   "source": [
    "def get_features_from_sentiment_stats(sentiments_per_day):\n",
    "  sentiment_features_df = sentiments_per_day[[\n",
    "      'mean_daily_positive_score',\n",
    "      'daily_positives_ratio', 'mean_daily_negative_score',\n",
    "      'daily_negatives_ratio',\n",
    "      'positivity', 'negativity', 'mood', 'weekly_buzz', 'monthly_buzz',\n",
    "      'weekly_relative_positivity', 'monthly_relative_positivity',\n",
    "      'weekly_relative_negativity', 'monthly_relative_negativity',\n",
    "      'weekly_relative_mood', 'monthly_relative_mood',\n",
    "      'difference_from_mood_week_ago', 'difference_from_mood_month_ago',\n",
    "      'nan_window_data', 'no_news_today'\n",
    "  ]]\n",
    "  return sentiment_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-22T13:31:35.291608Z",
     "start_time": "2022-10-22T13:31:35.279609Z"
    },
    "id": "-dZoMp2EFrRf"
   },
   "outputs": [],
   "source": [
    "intermediate_news_filename = 'intermediate_fetched_news.csv'\n",
    "\n",
    "def get_intermediate_sentiment_results_for_company(company, filename):\n",
    "  print(f'Checking intermediate results for {company} in {filename}')\n",
    "\n",
    "  if not os.path.isfile(filename):\n",
    "    print(f'No intermediate results file')\n",
    "    return None\n",
    "  \n",
    "  intermediate_df = pd.read_csv(filename)\n",
    "  company_intermediate_data = intermediate_df[intermediate_df['company'] == company]\n",
    "  if len(company_intermediate_data) > 0:\n",
    "    print(f'Found intermediate data')\n",
    "    return company_intermediate_data\n",
    "  else:\n",
    "    print(f'Did not find intermediate data')\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_intermediate_results_for_company(company, filename, df_to_save):\n",
    "  print(f'Saving intermediate results for {company} in {filename}')\n",
    "\n",
    "  if not os.path.isfile(filename):\n",
    "    print(f'No intermediate results file, creating one')\n",
    "    intermediate_results_df = df_to_save\n",
    "  else:\n",
    "    # loads the existing intermediate results, overwrites existing results, appends passed results\n",
    "    intermediate_results_df = pd.read_csv(filename)\n",
    "    length_before_overwrite = len(intermediate_results_df)\n",
    "    intermediate_results_df = intermediate_results_df[intermediate_results_df['company'] != company]\n",
    "    print(f'Overwrote {length_before_overwrite - len(intermediate_results_df)} records')\n",
    "    intermediate_results_df = pd.concat([intermediate_results_df, df_to_save], ignore_index=True)\n",
    "  intermediate_results_df.to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "def get_df_sentiments_of_companies(companies_list):\n",
    "  all_companies_news_df_list = []\n",
    "  for company in companies_list:\n",
    "    intermediate_results = get_intermediate_sentiment_results_for_company(company, intermediate_news_filename)\n",
    "    if intermediate_results is None:\n",
    "      # if there are no saved intermediate results, fetch ones\n",
    "      company_news_df = get_all_news_for_company(company)\n",
    "\n",
    "      company_news_sentiments = get_sentiment_for_series(company_news_df['summary'])\n",
    "      company_news_sentiments['datetime'] = pd.to_datetime(company_news_df['datetime'])\n",
    "      company_news_sentiments = company_news_sentiments.dropna()\n",
    "\n",
    "      sentiment_stats = get_sentiment_stats_per_day(company_news_sentiments)\n",
    "      sentiment_stats = fill_missing_days(sentiment_stats)\n",
    "      sentiment_stats = get_windowed_sentiment_stats(sentiment_stats)\n",
    "      sentiment_features_df = get_features_from_sentiment_stats(sentiment_stats)\n",
    "\n",
    "      sentiment_stats = sentiment_stats.reset_index()\n",
    "      sentiment_stats['company'] = company\n",
    "\n",
    "      save_intermediate_results_for_company(company,\n",
    "                                            intermediate_news_filename,\n",
    "                                            sentiment_stats)\n",
    "    else:\n",
    "      sentiment_stats = intermediate_results\n",
    "\n",
    "    all_companies_news_df_list.append(sentiment_stats)\n",
    "\n",
    "  all_companies_sentiment_df = pd.concat(all_companies_news_df_list, ignore_index=True)\n",
    "  return all_companies_sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKERPR0VylF0"
   },
   "source": [
    "## Combining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjtVmGsB2CKB",
    "outputId": "264fb13f-4c62-4b35-a0f0-a820c98c2463"
   },
   "outputs": [],
   "source": [
    "n_periods = 5\n",
    "stocks_data = get_companies_stocks(companies, n_periods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "tyYBCrVUA01y"
   },
   "outputs": [],
   "source": [
    "stocks_data['t'] = pd.to_datetime(stocks_data['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "eHTS2WQhBgaV"
   },
   "outputs": [],
   "source": [
    "stocks_data_1 = stocks_data[stocks_data['t'] > '2001-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "XcCjW6FrByNt"
   },
   "outputs": [],
   "source": [
    "stocks_data_1.to_csv('stocks_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MufUyCXKBr2k",
    "outputId": "3998d00c-947a-49bd-b834-14a5d4e2ce97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2421004 entries, 7833 to 2447\n",
      "Data columns (total 28 columns):\n",
      " #   Column   Dtype         \n",
      "---  ------   -----         \n",
      " 0   t        datetime64[ns]\n",
      " 1   target   float64       \n",
      " 2   1_c      float64       \n",
      " 3   1_h      float64       \n",
      " 4   1_l      float64       \n",
      " 5   1_o      float64       \n",
      " 6   1_v      float64       \n",
      " 7   2_c      float64       \n",
      " 8   2_h      float64       \n",
      " 9   2_l      float64       \n",
      " 10  2_o      float64       \n",
      " 11  2_v      float64       \n",
      " 12  3_c      float64       \n",
      " 13  3_h      float64       \n",
      " 14  3_l      float64       \n",
      " 15  3_o      float64       \n",
      " 16  3_v      float64       \n",
      " 17  4_c      float64       \n",
      " 18  4_h      float64       \n",
      " 19  4_l      float64       \n",
      " 20  4_o      float64       \n",
      " 21  4_v      float64       \n",
      " 22  5_c      float64       \n",
      " 23  5_h      float64       \n",
      " 24  5_l      float64       \n",
      " 25  5_o      float64       \n",
      " 26  5_v      float64       \n",
      " 27  company  object        \n",
      "dtypes: datetime64[ns](1), float64(26), object(1)\n",
      "memory usage: 567.9+ MB\n"
     ]
    }
   ],
   "source": [
    "stocks_data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T19:32:50.347844Z",
     "start_time": "2022-10-23T12:09:33.502540Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hFvE2u6P2dMU",
    "outputId": "6d180481-e87a-4da4-820a-1abd4e23a363",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_data = get_df_sentiments_of_companies(companies)\n",
    "display(sentiment_data)\n",
    "sentiment_data.to_csv('sentiment_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2Zf1Cfx5VVHs"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "stockenv",
   "language": "python",
   "name": "stockenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "129px",
    "width": "163px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
